{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanJ-02/Intelligence_Artificielle_B1IM/blob/main/4_Similitude_de_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFtqmRIoJs06"
      },
      "source": [
        "# Analyse de similarit√© entre texte\n",
        "\n",
        "## 1. Introduction & TF-IDF\n",
        "\n",
        "<img src='https://www.gstatic.com/aihub/tfhub/universal-sentence-encoder/example-similarity.png'>\n",
        "\n",
        "L'analyse de la similarit√© entre textes consiste √† mesurer la ressemblance ou la proximit√© entre deux ou plusieurs textes en utilisant des algorithmes math√©matiques et des m√©triques sp√©cifiques, cette analyse permet : \n",
        "- la **classification de documents** : Elle peut √™tre utilis√©e pour classer des documents en fonction de leur ressemblance, ce qui est utile pour organiser et classer des documents en fonction de leur sujet ou de leur contenu.\n",
        "\n",
        "- la **d√©tection de doublons** : Elle peut √™tre utilis√©e pour d√©tecter les documents en double ou similaires, ce qui est utile pour nettoyer les bases de donn√©es ou les archives de documents.\n",
        "\n",
        "- la **recommandation de contenu** : Elle peut √™tre utilis√©e pour recommander du contenu similaire √† l'utilisateur, bas√© sur son historique de recherche ou de lecture.\n",
        "\n",
        "- la **dettection de contenu** : Elle consiste √† trouver et √† identifier les textes ou les parties de textes qui sont identiques ou tr√®s similaires entre eux. Cela peut √™tre utile pour de nombreuses t√¢ches, telles que la suppression de doublons dans les bases de donn√©es, la d√©tection de plagiat dans les travaux acad√©miques, la v√©rification de l'originalit√© des articles de presse, et la mise en place de contr√¥les de qualit√© pour les sites Web et les applications.\n",
        "\n",
        "### 1.1 Bag Of Word\n",
        "\n",
        "Un **Bag of Words** (BoW) est une repr√©sentation fr√©quentielle des mots d'un document. Il s'agit d'un mod√®le simpliste qui se concentre sur la fr√©quence d'apparition de chaque mot dans le document psans prendre en compte l'ordre des mots.\n",
        "\n",
        "Il suffit de compter le nombre d'occurrences de chaque mot dans le document et stocker ces informations dans un vecteur. Chaque √©l√©ment du vecteur repr√©sente le nombre d'occurrences d'un mot donn√© dans le document.\n",
        "\n",
        "Les **BoW** sont souvent utilis√©s en NLP pour la vectorisation des textes, ce qui signifie qu'ils sont transform√©s en vecteurs num√©riques pouvant √™tre utilis√©s pour les algorithmes de classification et de clustering. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "41EPbA4DJs08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87a9f82-6064-4f01-9bde-73b537f59d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=0bd7dde321999cb857912bebbd2fe3f2306f0d4561b473a651c276e7c5f81ff4\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ua-CiagdJs08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a4c8171d-3853-40b4-9370-e097811b7bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.\\nNLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.\\nNLP is a complex field, as human language is highly ambiguous and context-dependent. To overcome these challenges, NLP models often rely on large amounts of annotated data and sophisticated algorithms to learn patterns and relationships in language.\\nDespite its challenges, NLP has the potential to revolutionize the way we interact with computers and unlock new possibilities for communication, education, and more.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Import the CountVectorizer depuis sklearn.feature_extraction.text\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = \"\"\"Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.\n",
        "NLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.\n",
        "NLP is a complex field, as human language is highly ambiguous and context-dependent. To overcome these challenges, NLP models often rely on large amounts of annotated data and sophisticated algorithms to learn patterns and relationships in language.\n",
        "Despite its challenges, NLP has the potential to revolutionize the way we interact with computers and unlock new possibilities for communication, education, and more.\"\"\"\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tAEKNjmtJs09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ae2532-e258-419f-ffeb-f07f4dbe1013"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.',\n",
              " 'NLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.',\n",
              " 'NLP is a complex field, as human language is highly ambiguous and context-dependent. To overcome these challenges, NLP models often rely on large amounts of annotated data and sophisticated algorithms to learn patterns and relationships in language.',\n",
              " 'Despite its challenges, NLP has the potential to revolutionize the way we interact with computers and unlock new possibilities for communication, education, and more.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "corpus = text.split('\\n')\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Q-Bwd1pJs0-",
        "outputId": "46dfe527-93dd-48f1-c245-653b1d0b21f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   algorithms  ambiguous  amounts  analysis  analyze  annotated  applications  \\\n",
              "0           0          0        0         0        0          0             0   \n",
              "1           1          0        0         1        1          0             1   \n",
              "2           1          1        1         0        0          1             0   \n",
              "3           0          0        0         0        0          0             0   \n",
              "\n",
              "   artificial  challenges  chatbots  ...  sophisticated  speech  structure  \\\n",
              "0           1           0         0  ...              0       0          0   \n",
              "1           0           0         1  ...              0       1          1   \n",
              "2           0           1         0  ...              1       0          0   \n",
              "3           0           1         0  ...              0       0          0   \n",
              "\n",
              "   techniques  text  translation  trees  understand  unlock  way  \n",
              "0           0     0            0      0           1       0    0  \n",
              "1           1     1            1      1           0       0    0  \n",
              "2           0     0            0      0           0       0    0  \n",
              "3           0     0            0      0           0       1    1  \n",
              "\n",
              "[4 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32338497-80cd-42d5-aee7-9591c9c61987\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algorithms</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>amounts</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analyze</th>\n",
              "      <th>annotated</th>\n",
              "      <th>applications</th>\n",
              "      <th>artificial</th>\n",
              "      <th>challenges</th>\n",
              "      <th>chatbots</th>\n",
              "      <th>...</th>\n",
              "      <th>sophisticated</th>\n",
              "      <th>speech</th>\n",
              "      <th>structure</th>\n",
              "      <th>techniques</th>\n",
              "      <th>text</th>\n",
              "      <th>translation</th>\n",
              "      <th>trees</th>\n",
              "      <th>understand</th>\n",
              "      <th>unlock</th>\n",
              "      <th>way</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows √ó 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32338497-80cd-42d5-aee7-9591c9c61987')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32338497-80cd-42d5-aee7-9591c9c61987 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32338497-80cd-42d5-aee7-9591c9c61987');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "BOW = vectorizer.fit_transform(corpus).toarray()\n",
        "\n",
        "# Convert the BOW array to a DataFrame\n",
        "BOW = pd.DataFrame(data=BOW, columns=vectorizer.get_feature_names())\n",
        "BOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IcIznbeyJs0-"
      },
      "outputs": [],
      "source": [
        "# Nombre de fois que le mot \"nlp\" apparait dans le corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwnB0JddJs0_"
      },
      "source": [
        "\n",
        "### 1.2 Term Frequency (TF)\n",
        "\n",
        "La fr√©quence des termes est le nombre d'occurrences d'un terme (par exemple un mot) dans un √©chantillon de texte, mais normalis√© par le nombre de mots dans cet √©chantillon. C'est tr√®s proche d'un Bag Of Words (BOW) : la principale diff√©rence est la normalisation.\n",
        "\n",
        "üëâüèª Voyons un exemple pour comprendre pourquoi nous aurions besoin de la normalisation. Supposons que nous recherchions la requ√™te \"amour\", et que nous souhaitions trouver la citation la plus pertinente parmi 3 citations diff√©rentes :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K1ofpBfnJs1A",
        "outputId": "b1806270-11b3-4da9-dd46-a60038ecf25a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26\n",
              "1    34\n",
              "2    24\n",
              "3    13\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "BOW.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rRR4uq8rJs1B",
        "outputId": "7336de9b-5378-4729-895b-cef600036b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   algorithms  ambiguous   amounts  analysis   analyze  annotated  \\\n",
              "0    0.000000   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "1    0.029412   0.000000  0.000000  0.029412  0.029412   0.000000   \n",
              "2    0.041667   0.041667  0.041667  0.000000  0.000000   0.041667   \n",
              "3    0.000000   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "\n",
              "   applications  artificial  challenges  chatbots  ...  sophisticated  \\\n",
              "0      0.000000    0.038462    0.000000  0.000000  ...       0.000000   \n",
              "1      0.029412    0.000000    0.000000  0.029412  ...       0.000000   \n",
              "2      0.000000    0.000000    0.041667  0.000000  ...       0.041667   \n",
              "3      0.000000    0.000000    0.076923  0.000000  ...       0.000000   \n",
              "\n",
              "     speech  structure  techniques      text  translation     trees  \\\n",
              "0  0.000000   0.000000    0.000000  0.000000     0.000000  0.000000   \n",
              "1  0.029412   0.029412    0.029412  0.029412     0.029412  0.029412   \n",
              "2  0.000000   0.000000    0.000000  0.000000     0.000000  0.000000   \n",
              "3  0.000000   0.000000    0.000000  0.000000     0.000000  0.000000   \n",
              "\n",
              "   understand    unlock       way  \n",
              "0    0.038462  0.000000  0.000000  \n",
              "1    0.000000  0.000000  0.000000  \n",
              "2    0.000000  0.000000  0.000000  \n",
              "3    0.000000  0.076923  0.076923  \n",
              "\n",
              "[4 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algorithms</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>amounts</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analyze</th>\n",
              "      <th>annotated</th>\n",
              "      <th>applications</th>\n",
              "      <th>artificial</th>\n",
              "      <th>challenges</th>\n",
              "      <th>chatbots</th>\n",
              "      <th>...</th>\n",
              "      <th>sophisticated</th>\n",
              "      <th>speech</th>\n",
              "      <th>structure</th>\n",
              "      <th>techniques</th>\n",
              "      <th>text</th>\n",
              "      <th>translation</th>\n",
              "      <th>trees</th>\n",
              "      <th>understand</th>\n",
              "      <th>unlock</th>\n",
              "      <th>way</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows √ó 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "TF = BOW.divide(BOW.sum(axis=1), axis=0)\n",
        "TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtmPolODJs1C"
      },
      "source": [
        "\n",
        "### 1.3 Inverse Document Frequency (IDF)\n",
        "\n",
        "**Inverse Document Frequency (IDF)** repr√©sente l'inverse de la fr√©quence √† laquelle un terme appara√Æt dans nos documents. Fondamentalement, l'IDF donnera donc un poids plus √©lev√© aux mots qui apparaissent rarement dans nos documents et r√©duira le poids des mots qui apparaissent fr√©quemment.\n",
        "\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/0f1b67e328e503d7dd2d10fdfff9ee75df88032a'>\n",
        "\n",
        "O√π D est le nombre total de documents dans le corpus et le d√©nominateur : nombre de documents o√π le terme t appara√Æt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tMIKqD5_Js1C",
        "outputId": "ed0afd0a-2b8a-438f-dbc2-dbfa2b6b6b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-34dcd5d82042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bow' is not defined"
          ]
        }
      ],
      "source": [
        "len(bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD7VNpeoJs1D"
      },
      "outputs": [],
      "source": [
        "bow.sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZSHoH5_Js1D"
      },
      "outputs": [],
      "source": [
        "bow = BOW\n",
        "bow[bow>1] = 1\n",
        "IDF = np.log(len(bow)/bow.sum(axis=0) +1)\n",
        "IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO45SxdfJs1E"
      },
      "outputs": [],
      "source": [
        "IDF.index[IDF.argmin()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Lgv9g8Js1E"
      },
      "source": [
        "\n",
        "### 1.4 **TF-IDF** (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "|       **`TF-IDF = TF √ó IDF`** |\n",
        "\n",
        "\n",
        "Pourquoi est-ce une bonne fonctionnalit√© ?\n",
        "\n",
        "D'une part, si vous recherchez un mot dans un corpus, plus ce mot appara√Æt, plus il a de chances d'√™tre pertinent : cela s'exprime par le Terme Fr√©quence.\n",
        "\n",
        "En revanche, si ce mot particulier appara√Æt dans tous les documents du corpus, il n'est peut-√™tre pas opportun de discriminer les diff√©rents documents : cela s'exprime par la Fr√©quence Inverse des Documents.\n",
        "\n",
        "‚û°Ô∏è En cons√©quence, la combinaison de TF et IDF semble √™tre un bon compromis et est une fonctionnalit√© largement utilis√©e dans le traitement du langage naturel.\n",
        "\n",
        "üëâüèª Suite √† notre exemple pr√©c√©dent, nous pouvons calculer le TF-IDF manuellement :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb6_sU6WJs1E"
      },
      "outputs": [],
      "source": [
        "TF*IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VnMrldtJs1F"
      },
      "source": [
        "___\n",
        "# Exercice \n",
        "\n",
        "\n",
        "1. Ajoutez √† la classe `Processing` une m√©thode `tfidf` qui prend en argument un corpus sous forme de list de chaine de caract√®re et qui retourne le traitement TF-IDF de ce corpus.\n",
        "\n",
        "- la m√©thode cr√©e un artibut `vectorizer=CountVectorizer(stop_words='english')`\n",
        "\n",
        "2. Testez votre code sur le jeu de donn√©es [suivant](https://drive.google.com/file/d/1Pz9YfRErwnkgD2qTk4Q0CCY_PPP7akqa/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw527A50Js1F"
      },
      "outputs": [],
      "source": [
        "#Cr√©ation d'une classe de pr√©traitement\n",
        "#Import de la fonction word_tokenize depuis la biblioth√®que nltk.tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "class Processing():\n",
        "    def tokenization(self, document, stem:bool=False, lemm:bool=False):\n",
        "        # Instanciation des objet stemm et lemm\n",
        "        stemmer = PorterStemmer()\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "        # Tokenization avec la fonction word_tokenize sur le document\n",
        "        document = document.lower()\n",
        "        tokens = word_tokenize(document)\n",
        "\n",
        "        # instanciation de la liste stop_words √† partir du module words (english)\n",
        "        stop_words = stopwords.words('english') + [',', '.', '!', ]\n",
        "\n",
        "        # Suppression des stop words avec une liste compr√©hension\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "        # Stemming\n",
        "        if stem:\n",
        "            tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        # Lemmatization\n",
        "        if lemm:\n",
        "            tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        return tokens\n",
        "    \n",
        "    def tfidf(self, corpus):\n",
        "        # Completez le code ici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BdEpJ5kJs1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL3MEdC-Js1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTUYhI4eJs1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NuHqozoJs1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG7YmbCHJs1H"
      },
      "outputs": [],
      "source": [
        "process = Processing()\n",
        "tfidf = process.tfidf(corpus)\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ1xqUVxJs1H"
      },
      "source": [
        "___\n",
        "## 2. M√©triques de Similarity\n",
        "\n",
        "Il existe de nombreuses fa√ßons de mesurer la similarit√© entre les documents , nous nous concentrerons uniquement sur deux d'entre elles :\n",
        "\n",
        "- Similitude Jaccard (principalement √† des fins p√©dagogiques mais nous ne l'utiliserons pas souvent)\n",
        "- Similitude cosinus (que nous avons d√©j√† vue avec nos algorithmes de recommandation).\n",
        "\n",
        "### 2.1 Jaccard Similarity\n",
        "\n",
        "La similarit√© Jaccard est une m√©trique tr√®s simple pour mesurer la similarit√© : la taille de l'intersection divis√©e par la taille de l'union des ensembles d'√©chantillons . En consid√©rant deux documents A et B, la Similitude Jaccard J sera :\n",
        "\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/b80075655821258068b67f3121a490dd65577083'>\n",
        "\n",
        "<img src='https://www.logamaths.fr/wp-content/uploads/2019/08/inresection.png'>\n",
        "\n",
        "‚ö†Ô∏è Pour √™tre pertinente, cette formule doit √™tre appliqu√©e uniquement sur des donn√©es pr√©trait√©es.\n",
        "\n",
        "üëâüèª Calculons la similarit√© Jaccard pour les documents suivants :\n",
        "\n",
        "A = 'Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.\n",
        "\n",
        "\n",
        "B = 'NLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.\n",
        "'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk6FgJL2Js1I"
      },
      "outputs": [],
      "source": [
        "A = model.tokenization(corpus[0], True)\n",
        "B = model.tokenization(corpus[1], True)\n",
        "\n",
        "# Compute the intersection and union\n",
        "intersection = set(A).intersection(B)\n",
        "print(f\"Intersection: {intersection}\")\n",
        "print()\n",
        "union = set(A).union(B)\n",
        "print(f\"Union: {union}\")\n",
        "print()\n",
        "# Compute and print the Jaccard Similarity\n",
        "J = len(intersection)/len(union)\n",
        "print('Jaccard Similarity:', J)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGMTXWFHJs1I"
      },
      "source": [
        "### 2.2. Cosine Similarity\n",
        "\n",
        "Le **Cosine Similarity** est un moyen plus puissant de mesurer la similarit√© entre les documents : il calcule le produit scalaire entre deux vecteurs repr√©sentant les documents plong√©s dans un l'espace vectoriel TFI-DF, chaque axe correspond √† un token.\n",
        "\n",
        "\n",
        "<img src = 'https://sites.temple.edu/tudsc/files/2017/03/cosine-equation.png'>\n",
        "\n",
        "<img src='https://www.oreilly.com/api/v2/epubs/9781788295758/files/assets/2b4a7a82-ad4c-4b2a-b808-e423a334de6f.png'>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUEMyEXsJs1I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "\n",
        "cosine_similarity([tfidf.iloc[0], tfidf.iloc[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2GJ4GIeJs1J"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "\n",
        "cos_sim = cosine_similarity(tfidf)\n",
        "cos_sim[cos_sim > 0.5] = 0\n",
        "sns.heatmap(cos_sim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhM2w1oqJs1J"
      },
      "source": [
        "___\n",
        "# Exercice \n",
        "\n",
        "1. Cr√©ez une m√©thode `cosine_similarity` √† la classe `Processing` qui prend en param√®tre une chaine de caract√®re et un corpus et retourne le document du corpus qui √† la plus grande similarit√©.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXTXoduhJs1J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0gxW05sJs1J"
      },
      "source": [
        "____\n",
        "## 3. Introduction aux chatbots\n",
        "\n",
        "<img src='https://f.hellowork.com/blogdumoderateur/2022/02/chatbot-definition-avantages-fonctions-marques.jpeg'>\n",
        "\n",
        "\n",
        "### 3.1. Cat√©gories de chatbots\n",
        "ü§ñ Les chatbots sont de plus en plus populaires ces derni√®res ann√©es. La plupart des sites de e-commerce ont d√©sormais leurs propres chatbots.\n",
        "\n",
        "Il existe principalement deux types de chatbots :\n",
        "\n",
        "- **chatbots bas√©s sur des r√®gles** : bas√©s sur un arbre de d√©cision avec des conditions pr√©d√©finies\n",
        "- **chatbots d'auto-apprentissage** : ils utilisent l'apprentissage automatique et peuvent comprendre du texte libre\n",
        "\n",
        "Dans la cat√©gorie auto-apprentissage, les chatbots peuvent √™tre subdivis√©s en deux sous-cat√©gories :\n",
        "\n",
        "- **Bots bas√©s sur la r√©cup√©ration** : ils r√©pondent en fonction d'une base de donn√©es pr√©d√©finie de r√©ponses\n",
        "- Les **bots g√©n√©ratifs** : ils g√©n√®rent des r√©ponses (g√©n√©ralement gr√¢ce √† des algorithmes de Deep Learning)\n",
        "\n",
        "‚û°Ô∏è Aujourd'hui, nous allons nous concentrer sur les robots bas√©s sur la r√©cup√©ration et utiliser nos outils nouvellement acquis pour cr√©er un chatbot de base.\n",
        "\n",
        "\n",
        "# Exercice\n",
        "\n",
        "1. Cr√©ez un programme de recommandation de contenu musical. A partir du jeu de donn√©es suivant : [coldplay.csv]() l'utilisateur doit avoir trois propositions de musique en fonction du text qu'il passe en entr√© du programme.\n",
        "\n",
        "D√©marche √† suivre :\n",
        "1. Cr√©ez dans la classe Processing une m√©thode `recommandation` qui prend en param√®tre `text` et `corpus` o√π text repr√©sente la saisie de l'utilisateur et corpus repr√©sente l'ensemble des Lyrics de coldplay.\n",
        "2. La m√©thode `recommandation` transforme le corpus en dataframe TFIDF.\n",
        "3. La m√©thode fait ensuite un `cosine_similarity` entre le text `text` et l'ensemblre du corpus.\n",
        "4. La m√©thode `recommandation` les 3 chansons avec le co√©ficient `cosine_similarity` le plus √©lev√©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvr-2R2OJs1K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "corpus = pd.read_csv('coldplay.csv').Lyrics\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzJrXbrGJs1K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}