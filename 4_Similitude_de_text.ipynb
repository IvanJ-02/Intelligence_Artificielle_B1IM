{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanJ-02/Intelligence_Artificielle_B1IM/blob/main/4_Similitude_de_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFtqmRIoJs06"
      },
      "source": [
        "# Analyse de similarité entre texte\n",
        "\n",
        "## 1. Introduction & TF-IDF\n",
        "\n",
        "<img src='https://www.gstatic.com/aihub/tfhub/universal-sentence-encoder/example-similarity.png'>\n",
        "\n",
        "L'analyse de la similarité entre textes consiste à mesurer la ressemblance ou la proximité entre deux ou plusieurs textes en utilisant des algorithmes mathématiques et des métriques spécifiques, cette analyse permet : \n",
        "- la **classification de documents** : Elle peut être utilisée pour classer des documents en fonction de leur ressemblance, ce qui est utile pour organiser et classer des documents en fonction de leur sujet ou de leur contenu.\n",
        "\n",
        "- la **détection de doublons** : Elle peut être utilisée pour détecter les documents en double ou similaires, ce qui est utile pour nettoyer les bases de données ou les archives de documents.\n",
        "\n",
        "- la **recommandation de contenu** : Elle peut être utilisée pour recommander du contenu similaire à l'utilisateur, basé sur son historique de recherche ou de lecture.\n",
        "\n",
        "- la **dettection de contenu** : Elle consiste à trouver et à identifier les textes ou les parties de textes qui sont identiques ou très similaires entre eux. Cela peut être utile pour de nombreuses tâches, telles que la suppression de doublons dans les bases de données, la détection de plagiat dans les travaux académiques, la vérification de l'originalité des articles de presse, et la mise en place de contrôles de qualité pour les sites Web et les applications.\n",
        "\n",
        "### 1.1 Bag Of Word\n",
        "\n",
        "Un **Bag of Words** (BoW) est une représentation fréquentielle des mots d'un document. Il s'agit d'un modèle simpliste qui se concentre sur la fréquence d'apparition de chaque mot dans le document psans prendre en compte l'ordre des mots.\n",
        "\n",
        "Il suffit de compter le nombre d'occurrences de chaque mot dans le document et stocker ces informations dans un vecteur. Chaque élément du vecteur représente le nombre d'occurrences d'un mot donné dans le document.\n",
        "\n",
        "Les **BoW** sont souvent utilisés en NLP pour la vectorisation des textes, ce qui signifie qu'ils sont transformés en vecteurs numériques pouvant être utilisés pour les algorithmes de classification et de clustering. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "41EPbA4DJs08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87a9f82-6064-4f01-9bde-73b537f59d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=0bd7dde321999cb857912bebbd2fe3f2306f0d4561b473a651c276e7c5f81ff4\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ua-CiagdJs08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a4c8171d-3853-40b4-9370-e097811b7bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.\\nNLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.\\nNLP is a complex field, as human language is highly ambiguous and context-dependent. To overcome these challenges, NLP models often rely on large amounts of annotated data and sophisticated algorithms to learn patterns and relationships in language.\\nDespite its challenges, NLP has the potential to revolutionize the way we interact with computers and unlock new possibilities for communication, education, and more.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Import the CountVectorizer depuis sklearn.feature_extraction.text\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = \"\"\"Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.\n",
        "NLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.\n",
        "NLP is a complex field, as human language is highly ambiguous and context-dependent. To overcome these challenges, NLP models often rely on large amounts of annotated data and sophisticated algorithms to learn patterns and relationships in language.\n",
        "Despite its challenges, NLP has the potential to revolutionize the way we interact with computers and unlock new possibilities for communication, education, and more.\"\"\"\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tAEKNjmtJs09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ae2532-e258-419f-ffeb-f07f4dbe1013"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.',\n",
              " 'NLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.',\n",
              " 'NLP is a complex field, as human language is highly ambiguous and context-dependent. To overcome these challenges, NLP models often rely on large amounts of annotated data and sophisticated algorithms to learn patterns and relationships in language.',\n",
              " 'Despite its challenges, NLP has the potential to revolutionize the way we interact with computers and unlock new possibilities for communication, education, and more.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "corpus = text.split('\\n')\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Q-Bwd1pJs0-",
        "outputId": "46dfe527-93dd-48f1-c245-653b1d0b21f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   algorithms  ambiguous  amounts  analysis  analyze  annotated  applications  \\\n",
              "0           0          0        0         0        0          0             0   \n",
              "1           1          0        0         1        1          0             1   \n",
              "2           1          1        1         0        0          1             0   \n",
              "3           0          0        0         0        0          0             0   \n",
              "\n",
              "   artificial  challenges  chatbots  ...  sophisticated  speech  structure  \\\n",
              "0           1           0         0  ...              0       0          0   \n",
              "1           0           0         1  ...              0       1          1   \n",
              "2           0           1         0  ...              1       0          0   \n",
              "3           0           1         0  ...              0       0          0   \n",
              "\n",
              "   techniques  text  translation  trees  understand  unlock  way  \n",
              "0           0     0            0      0           1       0    0  \n",
              "1           1     1            1      1           0       0    0  \n",
              "2           0     0            0      0           0       0    0  \n",
              "3           0     0            0      0           0       1    1  \n",
              "\n",
              "[4 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32338497-80cd-42d5-aee7-9591c9c61987\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algorithms</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>amounts</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analyze</th>\n",
              "      <th>annotated</th>\n",
              "      <th>applications</th>\n",
              "      <th>artificial</th>\n",
              "      <th>challenges</th>\n",
              "      <th>chatbots</th>\n",
              "      <th>...</th>\n",
              "      <th>sophisticated</th>\n",
              "      <th>speech</th>\n",
              "      <th>structure</th>\n",
              "      <th>techniques</th>\n",
              "      <th>text</th>\n",
              "      <th>translation</th>\n",
              "      <th>trees</th>\n",
              "      <th>understand</th>\n",
              "      <th>unlock</th>\n",
              "      <th>way</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32338497-80cd-42d5-aee7-9591c9c61987')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32338497-80cd-42d5-aee7-9591c9c61987 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32338497-80cd-42d5-aee7-9591c9c61987');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "BOW = vectorizer.fit_transform(corpus).toarray()\n",
        "\n",
        "# Convert the BOW array to a DataFrame\n",
        "BOW = pd.DataFrame(data=BOW, columns=vectorizer.get_feature_names())\n",
        "BOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IcIznbeyJs0-"
      },
      "outputs": [],
      "source": [
        "# Nombre de fois que le mot \"nlp\" apparait dans le corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwnB0JddJs0_"
      },
      "source": [
        "\n",
        "### 1.2 Term Frequency (TF)\n",
        "\n",
        "La fréquence des termes est le nombre d'occurrences d'un terme (par exemple un mot) dans un échantillon de texte, mais normalisé par le nombre de mots dans cet échantillon. C'est très proche d'un Bag Of Words (BOW) : la principale différence est la normalisation.\n",
        "\n",
        "👉🏻 Voyons un exemple pour comprendre pourquoi nous aurions besoin de la normalisation. Supposons que nous recherchions la requête \"amour\", et que nous souhaitions trouver la citation la plus pertinente parmi 3 citations différentes :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K1ofpBfnJs1A",
        "outputId": "b1806270-11b3-4da9-dd46-a60038ecf25a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26\n",
              "1    34\n",
              "2    24\n",
              "3    13\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "BOW.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rRR4uq8rJs1B",
        "outputId": "7336de9b-5378-4729-895b-cef600036b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   algorithms  ambiguous   amounts  analysis   analyze  annotated  \\\n",
              "0    0.000000   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "1    0.029412   0.000000  0.000000  0.029412  0.029412   0.000000   \n",
              "2    0.041667   0.041667  0.041667  0.000000  0.000000   0.041667   \n",
              "3    0.000000   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "\n",
              "   applications  artificial  challenges  chatbots  ...  sophisticated  \\\n",
              "0      0.000000    0.038462    0.000000  0.000000  ...       0.000000   \n",
              "1      0.029412    0.000000    0.000000  0.029412  ...       0.000000   \n",
              "2      0.000000    0.000000    0.041667  0.000000  ...       0.041667   \n",
              "3      0.000000    0.000000    0.076923  0.000000  ...       0.000000   \n",
              "\n",
              "     speech  structure  techniques      text  translation     trees  \\\n",
              "0  0.000000   0.000000    0.000000  0.000000     0.000000  0.000000   \n",
              "1  0.029412   0.029412    0.029412  0.029412     0.029412  0.029412   \n",
              "2  0.000000   0.000000    0.000000  0.000000     0.000000  0.000000   \n",
              "3  0.000000   0.000000    0.000000  0.000000     0.000000  0.000000   \n",
              "\n",
              "   understand    unlock       way  \n",
              "0    0.038462  0.000000  0.000000  \n",
              "1    0.000000  0.000000  0.000000  \n",
              "2    0.000000  0.000000  0.000000  \n",
              "3    0.000000  0.076923  0.076923  \n",
              "\n",
              "[4 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algorithms</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>amounts</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analyze</th>\n",
              "      <th>annotated</th>\n",
              "      <th>applications</th>\n",
              "      <th>artificial</th>\n",
              "      <th>challenges</th>\n",
              "      <th>chatbots</th>\n",
              "      <th>...</th>\n",
              "      <th>sophisticated</th>\n",
              "      <th>speech</th>\n",
              "      <th>structure</th>\n",
              "      <th>techniques</th>\n",
              "      <th>text</th>\n",
              "      <th>translation</th>\n",
              "      <th>trees</th>\n",
              "      <th>understand</th>\n",
              "      <th>unlock</th>\n",
              "      <th>way</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57579eb2-fc58-4dff-88b6-ca2cd4fcfebf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "TF = BOW.divide(BOW.sum(axis=1), axis=0)\n",
        "TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtmPolODJs1C"
      },
      "source": [
        "\n",
        "### 1.3 Inverse Document Frequency (IDF)\n",
        "\n",
        "**Inverse Document Frequency (IDF)** représente l'inverse de la fréquence à laquelle un terme apparaît dans nos documents. Fondamentalement, l'IDF donnera donc un poids plus élevé aux mots qui apparaissent rarement dans nos documents et réduira le poids des mots qui apparaissent fréquemment.\n",
        "\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/0f1b67e328e503d7dd2d10fdfff9ee75df88032a'>\n",
        "\n",
        "Où D est le nombre total de documents dans le corpus et le dénominateur : nombre de documents où le terme t apparaît."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tMIKqD5_Js1C",
        "outputId": "ed0afd0a-2b8a-438f-dbc2-dbfa2b6b6b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-34dcd5d82042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bow' is not defined"
          ]
        }
      ],
      "source": [
        "len(bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD7VNpeoJs1D"
      },
      "outputs": [],
      "source": [
        "bow.sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZSHoH5_Js1D"
      },
      "outputs": [],
      "source": [
        "bow = BOW\n",
        "bow[bow>1] = 1\n",
        "IDF = np.log(len(bow)/bow.sum(axis=0) +1)\n",
        "IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO45SxdfJs1E"
      },
      "outputs": [],
      "source": [
        "IDF.index[IDF.argmin()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Lgv9g8Js1E"
      },
      "source": [
        "\n",
        "### 1.4 **TF-IDF** (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "|       **`TF-IDF = TF × IDF`** |\n",
        "\n",
        "\n",
        "Pourquoi est-ce une bonne fonctionnalité ?\n",
        "\n",
        "D'une part, si vous recherchez un mot dans un corpus, plus ce mot apparaît, plus il a de chances d'être pertinent : cela s'exprime par le Terme Fréquence.\n",
        "\n",
        "En revanche, si ce mot particulier apparaît dans tous les documents du corpus, il n'est peut-être pas opportun de discriminer les différents documents : cela s'exprime par la Fréquence Inverse des Documents.\n",
        "\n",
        "➡️ En conséquence, la combinaison de TF et IDF semble être un bon compromis et est une fonctionnalité largement utilisée dans le traitement du langage naturel.\n",
        "\n",
        "👉🏻 Suite à notre exemple précédent, nous pouvons calculer le TF-IDF manuellement :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb6_sU6WJs1E"
      },
      "outputs": [],
      "source": [
        "TF*IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VnMrldtJs1F"
      },
      "source": [
        "___\n",
        "# Exercice \n",
        "\n",
        "\n",
        "1. Ajoutez à la classe `Processing` une méthode `tfidf` qui prend en argument un corpus sous forme de list de chaine de caractère et qui retourne le traitement TF-IDF de ce corpus.\n",
        "\n",
        "- la méthode crée un artibut `vectorizer=CountVectorizer(stop_words='english')`\n",
        "\n",
        "2. Testez votre code sur le jeu de données [suivant](https://drive.google.com/file/d/1Pz9YfRErwnkgD2qTk4Q0CCY_PPP7akqa/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw527A50Js1F"
      },
      "outputs": [],
      "source": [
        "#Création d'une classe de prétraitement\n",
        "#Import de la fonction word_tokenize depuis la bibliothèque nltk.tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "class Processing():\n",
        "    def tokenization(self, document, stem:bool=False, lemm:bool=False):\n",
        "        # Instanciation des objet stemm et lemm\n",
        "        stemmer = PorterStemmer()\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "        # Tokenization avec la fonction word_tokenize sur le document\n",
        "        document = document.lower()\n",
        "        tokens = word_tokenize(document)\n",
        "\n",
        "        # instanciation de la liste stop_words à partir du module words (english)\n",
        "        stop_words = stopwords.words('english') + [',', '.', '!', ]\n",
        "\n",
        "        # Suppression des stop words avec une liste compréhension\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "        # Stemming\n",
        "        if stem:\n",
        "            tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        # Lemmatization\n",
        "        if lemm:\n",
        "            tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        return tokens\n",
        "    \n",
        "    def tfidf(self, corpus):\n",
        "        # Completez le code ici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BdEpJ5kJs1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL3MEdC-Js1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTUYhI4eJs1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NuHqozoJs1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG7YmbCHJs1H"
      },
      "outputs": [],
      "source": [
        "process = Processing()\n",
        "tfidf = process.tfidf(corpus)\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ1xqUVxJs1H"
      },
      "source": [
        "___\n",
        "## 2. Métriques de Similarity\n",
        "\n",
        "Il existe de nombreuses façons de mesurer la similarité entre les documents , nous nous concentrerons uniquement sur deux d'entre elles :\n",
        "\n",
        "- Similitude Jaccard (principalement à des fins pédagogiques mais nous ne l'utiliserons pas souvent)\n",
        "- Similitude cosinus (que nous avons déjà vue avec nos algorithmes de recommandation).\n",
        "\n",
        "### 2.1 Jaccard Similarity\n",
        "\n",
        "La similarité Jaccard est une métrique très simple pour mesurer la similarité : la taille de l'intersection divisée par la taille de l'union des ensembles d'échantillons . En considérant deux documents A et B, la Similitude Jaccard J sera :\n",
        "\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/b80075655821258068b67f3121a490dd65577083'>\n",
        "\n",
        "<img src='https://www.logamaths.fr/wp-content/uploads/2019/08/inresection.png'>\n",
        "\n",
        "⚠️ Pour être pertinente, cette formule doit être appliquée uniquement sur des données prétraitées.\n",
        "\n",
        "👉🏻 Calculons la similarité Jaccard pour les documents suivants :\n",
        "\n",
        "A = 'Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. The goal of NLP is to make it possible for computers to understand, interpret, and generate human language.\n",
        "\n",
        "\n",
        "B = 'NLP applications include text classification, sentiment analysis, language translation, named entity recognition, speech recognition, and chatbots. NLP techniques rely on machine learning algorithms, such as decision trees, random forests, neural networks, and deep learning, to analyze and model the structure and meaning of language.\n",
        "'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk6FgJL2Js1I"
      },
      "outputs": [],
      "source": [
        "A = model.tokenization(corpus[0], True)\n",
        "B = model.tokenization(corpus[1], True)\n",
        "\n",
        "# Compute the intersection and union\n",
        "intersection = set(A).intersection(B)\n",
        "print(f\"Intersection: {intersection}\")\n",
        "print()\n",
        "union = set(A).union(B)\n",
        "print(f\"Union: {union}\")\n",
        "print()\n",
        "# Compute and print the Jaccard Similarity\n",
        "J = len(intersection)/len(union)\n",
        "print('Jaccard Similarity:', J)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGMTXWFHJs1I"
      },
      "source": [
        "### 2.2. Cosine Similarity\n",
        "\n",
        "Le **Cosine Similarity** est un moyen plus puissant de mesurer la similarité entre les documents : il calcule le produit scalaire entre deux vecteurs représentant les documents plongés dans un l'espace vectoriel TFI-DF, chaque axe correspond à un token.\n",
        "\n",
        "\n",
        "<img src = 'https://sites.temple.edu/tudsc/files/2017/03/cosine-equation.png'>\n",
        "\n",
        "<img src='https://www.oreilly.com/api/v2/epubs/9781788295758/files/assets/2b4a7a82-ad4c-4b2a-b808-e423a334de6f.png'>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUEMyEXsJs1I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "\n",
        "cosine_similarity([tfidf.iloc[0], tfidf.iloc[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2GJ4GIeJs1J"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "\n",
        "cos_sim = cosine_similarity(tfidf)\n",
        "cos_sim[cos_sim > 0.5] = 0\n",
        "sns.heatmap(cos_sim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhM2w1oqJs1J"
      },
      "source": [
        "___\n",
        "# Exercice \n",
        "\n",
        "1. Créez une méthode `cosine_similarity` à la classe `Processing` qui prend en paramètre une chaine de caractère et un corpus et retourne le document du corpus qui à la plus grande similarité.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXTXoduhJs1J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0gxW05sJs1J"
      },
      "source": [
        "____\n",
        "## 3. Introduction aux chatbots\n",
        "\n",
        "<img src='https://f.hellowork.com/blogdumoderateur/2022/02/chatbot-definition-avantages-fonctions-marques.jpeg'>\n",
        "\n",
        "\n",
        "### 3.1. Catégories de chatbots\n",
        "🤖 Les chatbots sont de plus en plus populaires ces dernières années. La plupart des sites de e-commerce ont désormais leurs propres chatbots.\n",
        "\n",
        "Il existe principalement deux types de chatbots :\n",
        "\n",
        "- **chatbots basés sur des règles** : basés sur un arbre de décision avec des conditions prédéfinies\n",
        "- **chatbots d'auto-apprentissage** : ils utilisent l'apprentissage automatique et peuvent comprendre du texte libre\n",
        "\n",
        "Dans la catégorie auto-apprentissage, les chatbots peuvent être subdivisés en deux sous-catégories :\n",
        "\n",
        "- **Bots basés sur la récupération** : ils répondent en fonction d'une base de données prédéfinie de réponses\n",
        "- Les **bots génératifs** : ils génèrent des réponses (généralement grâce à des algorithmes de Deep Learning)\n",
        "\n",
        "➡️ Aujourd'hui, nous allons nous concentrer sur les robots basés sur la récupération et utiliser nos outils nouvellement acquis pour créer un chatbot de base.\n",
        "\n",
        "\n",
        "# Exercice\n",
        "\n",
        "1. Créez un programme de recommandation de contenu musical. A partir du jeu de données suivant : [coldplay.csv]() l'utilisateur doit avoir trois propositions de musique en fonction du text qu'il passe en entré du programme.\n",
        "\n",
        "Démarche à suivre :\n",
        "1. Créez dans la classe Processing une méthode `recommandation` qui prend en paramètre `text` et `corpus` où text représente la saisie de l'utilisateur et corpus représente l'ensemble des Lyrics de coldplay.\n",
        "2. La méthode `recommandation` transforme le corpus en dataframe TFIDF.\n",
        "3. La méthode fait ensuite un `cosine_similarity` entre le text `text` et l'ensemblre du corpus.\n",
        "4. La méthode `recommandation` les 3 chansons avec le coéficient `cosine_similarity` le plus élevé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvr-2R2OJs1K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "corpus = pd.read_csv('coldplay.csv').Lyrics\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzJrXbrGJs1K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}